---
title: "Linear Algebra with Torch"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{linear_algebra_with_torch}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(rTorch)
```


## Scalars

```{r}
torch$scalar_tensor(2.78654)

torch$scalar_tensor(0L)

torch$scalar_tensor(1L)

torch$scalar_tensor(TRUE)

torch$scalar_tensor(FALSE)
```

## Vectors

```{r}
v <- c(0, 1, 2, 3, 4, 5)
torch$as_tensor(v)
```


```{r}
# row-vector
(mr <- matrix(1:10, nrow=1))
torch$as_tensor(mr)
torch$as_tensor(mr)$shape
```

```{r}
# column-vector
(mc <- matrix(1:10, ncol=1))
torch$as_tensor(mc)
torch$as_tensor(mc)$shape
```

## Matrices

```{r}
(m1 <- matrix(1:24, nrow = 3, byrow = TRUE))
(t1 <- torch$as_tensor(m1))
torch$as_tensor(m1)$shape
torch$as_tensor(m1)$size()
dim(torch$as_tensor(m1))
length(torch$as_tensor(m1))
```

```{r}
(m2 <- matrix(0:99, ncol = 10))
(t2 <- torch$as_tensor(m2))
t2$shape
dim(torch$as_tensor(m2))
```

```{r}
m1[1, 1]
m2[1, 1]
```

```{r}
t1[1, 1]
t2[1, 1]
```

## 3D+ tensors

```{r}
# RGB color image has three axes 
(img <- torch$rand(3L, 28L, 28L))
img$shape
```

```{r}
img[1, 1, 1]
img[3, 28, 28]
```


## Transpose of a matrix

```{r}
(m3 <- matrix(1:25, ncol = 5))

# transpose
tm3 <- t(m3)
tm3
```

```{r}
(t3 <- torch$as_tensor(m3))

tt3 <- t3$transpose(dim0 = 0L, dim1 = 1L)
tt3
```

```{r}
tm3 == tt3$numpy()   # convert first the tensor to numpy
```

## Vectors, special case of a matrix

```{r}
m2 <- matrix(0:99, ncol = 10)
(t2 <- torch$as_tensor(m2))

# in R
(v1 <- m2[, 1])
(v2 <- m2[10, ])
```

```{r}
# PyTorch

t2c <- t2[, 1]
t2r <- t2[10, ]

t2c
t2r
```

In vectors, the vector and its transpose are equal.

```{r}
tt2r <- t2r$transpose(dim0 = 0L, dim1 = 0L)
tt2r
```

```{r}
# a tensor of booleans. is vector equal to its transposed?
t2r == tt2r
```

## Tensor addition

```{r}
(x = torch$ones(5L, 4L))
(y = torch$ones(5L, 4L))

x + y
```

$$A + B = B + A$$

```{r}
x + y == y + x
```

## Add a scalar to a tensor

```{r}
s <- 0.5    # scalar
x + s
```

```{r}
# scalar multiplying two tensors
s * (x + y)
```

## Multiplying tensors

$$A * B = B * A$$

```{r}
(x = torch$ones(5L, 4L))
(y = torch$ones(5L, 4L))

```

```{r}
(z = 2 * x + 4 * y)
```


```{r}
x * y == y * x
```

## Dot product

$$dot(a,b)_{i,j,k,a,b,c} = \sum_m a_{i,j,k,m}b_{a,b,m,c}$$

```{r}
torch$dot(torch$tensor(c(2, 3)), torch$tensor(c(2, 1)))
```

```{r}
a <- np$array(list(list(1, 2), list(3, 4)))
a
b <- np$array(list(list(1, 2), list(3, 4)))
b

np$dot(a, b)
```

`torch.dot()` treats both a and b as 1D vectors (irrespective of their original shape) and computes their inner product. 

```{r, error=TRUE}
at <- torch$as_tensor(a)
bt <- torch$as_tensor(b)

torch$dot(at, bt)
# at %.*% bt
```

If we perform the same dot product operation in Python, we get the same error:


```{python, error=TRUE}
import torch
import numpy as np

a = np.array([[1, 2], [3, 4]])
a
b = np.array([[1, 2], [3, 4]])
b

np.dot(a, b)

at = torch.as_tensor(a)
bt = torch.as_tensor(b)

at
bt

torch.dot(at, bt)
```


```{r, error=TRUE}
a <- torch$Tensor(list(list(1, 2), list(3, 4)))
b <- torch$Tensor(c(c(1, 2), c(3, 4)))
c <- torch$Tensor(list(list(11, 12), list(13, 14)))

a
b
torch$dot(a, b)

# this is another way of performing dot product in PyTorch
# a$dot(a)
```

```{r, error=TRUE}
o1 <- torch$ones(2L, 2L)
o2 <- torch$ones(2L, 2L)

o1
o2

torch$dot(o1, o2)
o1$dot(o2)
```


```{r}
# 1D tensors work fine
r = torch$dot(torch$Tensor(list(4L, 2L, 4L)), torch$Tensor(list(3L, 4L, 1L)))
r
```

```{r}
## mm and matmul seem to address the dot product we are looking for in tensors
a = torch$randn(2L, 3L)
b = torch$randn(3L, 4L)

a$mm(b)
a$matmul(b)
```

Here is agood explanation: https://stackoverflow.com/a/44525687/5270873


```{r}
abt <- torch$mm(a, b)$transpose(dim0=0L, dim1=1L)
abt
```

```{r}
at <- a$transpose(dim0=0L, dim1=1L)
bt <- b$transpose(dim0=0L, dim1=1L)

btat <- torch$matmul(bt, at)
btat
```

$$(A B)^T = B^T A^T$$

```{r}
torch$allclose(abt, btat, rtol=0.0001)
```

